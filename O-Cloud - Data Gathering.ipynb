{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac90b272-018b-44ff-84b4-6823c857b956",
   "metadata": {},
   "source": [
    "# O-Cloud Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfead79",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ad5065",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T09:14:53.796207123Z",
     "start_time": "2023-08-16T09:13:25.634925702Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Run the pip command and capture the output\n",
    "installedpackages = subprocess.run(['pip', 'freeze'], stdout=subprocess.PIPE, text=True).stdout\n",
    "# Read requirements from file\n",
    "with open(\"./requirements.txt\", 'r') as file:\n",
    "    requirements = file.read()\n",
    "# Split the multi-line string into a list of lines\n",
    "lines = requirements.splitlines()\n",
    "# Check if requirements are installed line by line \n",
    "for line in lines:\n",
    "    index = installedpackages.find(line)\n",
    "    if index == -1:\n",
    "        # Install dependecies from requirements.txt\n",
    "        %pip install -r ./requirements.txt > /dev/null\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5456e227",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T09:14:57.739963712Z",
     "start_time": "2023-08-16T09:14:53.799759077Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from OCloud_Data_Gathering import *\n",
    "from plotly.offline import init_notebook_mode\n",
    "from stix2 import FileSystemSource\n",
    "%matplotlib inline\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a62a2e",
   "metadata": {},
   "source": [
    "#### `pull_clone_gitrepo(directory, repo)`\n",
    "\n",
    "This method manages a Git repository, either by cloning it if the directory doesn't exist or pulling changes if it does.\n",
    "\n",
    "##### Parameters\n",
    "\n",
    "- `directory`: The target directory for the repository.\n",
    "- `repo`: The Git repository URL.\n",
    "\n",
    "##### Behavior\n",
    "\n",
    "- If `directory` doesn't exist, the method clones `repo` into it using `Repo.clone_from()`.\n",
    "- If `directory` exists and is a valid Git repository, the method pulls changes using `repo.remotes.origin.pull()`.\n",
    "- If `directory` exists but is not a Git repository, it is deleted and `repo` is cloned into it.\n",
    "\n",
    "This method ensures proper management of Git repositories in the specified directory.\n",
    "\n",
    "#### `generate_techniques_dataframe()`\n",
    "\n",
    "This method retrieves techniques data from the ATT&CK framework and returns it as a Pandas DataFrame.\n",
    "\n",
    "##### Behavior\n",
    "\n",
    "1. Downloads and parses ATT&CK STIX data of version 4.0 for the enterprise edition.\n",
    "2. Converts the parsed data into Pandas DataFrames for techniques, related relationships, and citations.\n",
    "3. Returns the Pandas DataFrame containing techniques data.\n",
    "\n",
    "This method simplifies the retrieval and organization of techniques data from ATT&CK into a structured DataFrame format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "foreign-farmer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T09:15:04.161129310Z",
     "start_time": "2023-08-16T09:14:57.400111081Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-08-25 12:19:45.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmitreattack.attackToExcel.attackToExcel\u001b[0m:\u001b[36mget_stix_data\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mDownloading ATT&CK data from github.com/mitre/cti\u001b[0m\n",
      "parsing techniques: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 244/244 [00:00<00:00, 52463.74it/s]\n",
      "parsing relationships for type=technique: 100%|███████████████████████████████████████████████████████████████████████████████████████| 4852/4852 [00:00<00:00, 145335.60it/s]\n"
     ]
    }
   ],
   "source": [
    "##Download CTI data from GitHub\n",
    "pull_clone_gitrepo('./data', 'https://github.com/mitre/cti')\n",
    "fs = FileSystemSource('./data/capec/2.1')\n",
    "techniques_df = generate_techniques_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a7aa2",
   "metadata": {},
   "source": [
    "#### `get_grouped_o_cloud_technique(file, dropDrop_duplicates: bool = False)`\n",
    "\n",
    "This method extracts and groups O-Cloud threat data from a CSV file, allowing for further analysis.\n",
    "\n",
    "##### Parameters\n",
    "\n",
    "- `file`: The path to the CSV file containing O-Cloud threat data.\n",
    "- `dropDrop_duplicates`: An optional boolean parameter to drop duplicate technique entries. Default is `False`.\n",
    "\n",
    "##### Behavior\n",
    "\n",
    "1. Reads O-Cloud threat data from the specified CSV file, using the \"Name\" column as an index.\n",
    "2. Optionally drops duplicate entries based on the \"Technique\" column if `dropDrop_duplicates` is set to `True`.\n",
    "3. Groups the data by the \"Name\" column and returns the grouped object.\n",
    "\n",
    "This method facilitates efficient analysis of O-Cloud threat data by grouping it based on specified criteria.\n",
    "\n",
    "\n",
    "#### `get_technique_capecs_id(grouped, techniques_df)`\n",
    "\n",
    "This method retrieves CAPEC IDs associated with specific techniques from grouped data.\n",
    "\n",
    "##### Parameters\n",
    "\n",
    "- `grouped`: Grouped data containing techniques.\n",
    "- `techniques_df`: DataFrame containing technique details.\n",
    "\n",
    "##### Behavior\n",
    "\n",
    "1. Initializes an empty list `techniques_capecs` to store technique and CAPEC ID associations.\n",
    "2. Iterates through each group in the provided `grouped` data.\n",
    "3. For each technique in the group, extracts associated CAPEC IDs from `techniques_df`.\n",
    "4. Handles instances where CAPEC IDs might be in comma-separated format.\n",
    "5. Appends tuples of technique and CAPEC IDs to the `techniques_capecs` list.\n",
    "6. Returns the list of technique and CAPEC ID associations.\n",
    "\n",
    "This method aids in obtaining CAPEC IDs linked to specific techniques for further analysis.\n",
    "\n",
    "\n",
    "#### `write_ids_to_file(techniques_capecs, file)`\n",
    "\n",
    "This method writes technique and CAPEC ID associations to a CSV file.\n",
    "\n",
    "##### Parameters\n",
    "\n",
    "- `techniques_capecs`: List of tuples containing technique and associated CAPEC IDs.\n",
    "- `file`: Path to the CSV file to be written.\n",
    "\n",
    "##### Behavior\n",
    "\n",
    "1. Opens the specified CSV file in write mode.\n",
    "2. Initializes a CSV writer and writes a header row with column names ('Technique ID', 'CAPEC ID').\n",
    "3. Iterates through each tuple in `techniques_capecs`.\n",
    "4. For tuples with non-empty CAPEC IDs, writes each combination of technique and CAPEC ID to the CSV.\n",
    "5. Closes the file after writing.\n",
    "\n",
    "This method efficiently creates a CSV file containing technique and CAPEC ID associations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "directed-recovery",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T09:15:04.221205928Z",
     "start_time": "2023-08-16T09:15:04.167370717Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('T1498', []), ('T1552', []), ('T1609', []), ('T1204', []), ('T1068', ['CAPEC-69']), ('T1078', ['CAPEC-560']), ('T1003', ['CAPEC-567']), ('T1614', []), ('T1195', ['CAPEC-437', 'CAPEC-438', 'CAPEC-439']), ('T1525', []), ('T1610', []), ('T1612', []), ('T1040', ['CAPEC-158']), ('T1600', []), ('T1613', []), ('T1082', ['CAPEC-311']), ('T1580', []), ('T1070', ['CAPEC-93']), ('T1049', []), ('T1619', []), ('T1046', []), ('T1036', []), ('T1496', []), ('T1542', []), ('T1495', []), ('T1016', ['CAPEC-309']), ('T1611', []), ('T1538', []), ('T1530', []), ('T1499', ['CAPEC-227', 'CAPEC-131', 'CAPEC-130', 'CAPEC-125']), ('T1578', [])]\n"
     ]
    }
   ],
   "source": [
    "grouped = get_grouped_o_cloud_technique(file='./mapping/o_cloud_technique_mapping_without_subtechniques.csv', drop_duplicates=True)\n",
    "techniques_capecs = get_technique_capecs_id(grouped,techniques_df)\n",
    "print(techniques_capecs)\n",
    "write_ids_to_file(techniques_capecs, file ='./mapping/o_cloud_capecs_per_technique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "julian-saturn",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T09:15:04.234703120Z",
     "start_time": "2023-08-16T09:15:04.222901277Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Techniques: 31\n",
      "Empty Techniques: 22\n",
      "CAPECs: 14\n"
     ]
    }
   ],
   "source": [
    "print_stats(techniques_capecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e416e10",
   "metadata": {},
   "source": [
    "#### `find_cwe_for_capec(techniques_capecs)`\n",
    "\n",
    "This method fetches related CWEs and CVEs for given CAPEC IDs.\n",
    "\n",
    "##### Parameters\n",
    "\n",
    "- `techniques_capecs`: List of tuples containing technique and associated CAPEC IDs.\n",
    "\n",
    "##### Behavior\n",
    "\n",
    "1. Initializes `capec_list` and `list_of_tinfos` to store collected data.\n",
    "2. Records the start time and logs the process initiation.\n",
    "3. Iterates through tuples in `techniques_capecs` to retrieve associated CWEs and CVEs.\n",
    "4. For each tuple with non-empty CAPEC IDs, fetches relevant CVE data.\n",
    "5. Appends the collected information to `capec_list` and associates it with the technique.\n",
    "6. Gathers all technique-related data in `list_of_tinfos`.\n",
    "7. Records the end time, calculates runtime, and logs completion.\n",
    "8. Returns a dictionary containing scan date, runtime, and related data.\n",
    "\n",
    "This method facilitates the retrieval of CWEs and CVEs associated with specific CAPEC IDs, providing valuable threat information.\n",
    "\n",
    "\n",
    "#### `write_dict_to_file(t_cwe_cve_dict, file)`\n",
    "\n",
    "This method writes a dictionary to a JSON file using a custom encoder.\n",
    "\n",
    "##### Parameters\n",
    "\n",
    "- `t_cwe_cve_dict`: The dictionary containing data to be written to the JSON file.\n",
    "- `file`: The path to the JSON file to be written.\n",
    "\n",
    "##### Behavior\n",
    "\n",
    "1. Opens the specified JSON file in write mode using a context manager.\n",
    "2. Uses the `json.dump()` function to serialize the `t_cwe_cve_dict` dictionary and write it to the file.\n",
    "3. The `cve_custom_encoder` class is used to handle custom encoding if required.\n",
    "\n",
    "This method provides a straightforward way to save a dictionary as JSON data in a file with optional custom encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fabulous-portal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T09:15:04.755256125Z",
     "start_time": "2023-08-16T09:15:04.236938051Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fetching CAPEC'S -> CWE'S -> CVE'S for given CAPEC-IDS...\n",
      "\n",
      "Searching CVE's for CAPEC-69\n",
      "Found: CVE-2007-4217, CVE-2008-1877, CVE-2007-5159, CVE-2008-4638, CVE-2008-0162, CVE-2008-0368, CVE-2007-3931, CVE-2020-3812, \n",
      "\n",
      "\n",
      "Searching CVE's for CAPEC-560\n",
      "Found: CVE-2007-0681, CVE-2000-0944, CVE-2005-3435, CVE-2005-0408, CVE-1999-1152, CVE-2001-1291, CVE-2001-0395, CVE-2001-1339, CVE-2002-0628, CVE-1999-1324, \n",
      "\n",
      "\n",
      "Searching CVE's for CAPEC-567\n",
      "Found: \n",
      "\n",
      "\n",
      "Searching CVE's for CAPEC-437\n",
      "Found: \n",
      "\n",
      "\n",
      "Searching CVE's for CAPEC-438\n",
      "Found: \n",
      "\n",
      "\n",
      "Searching CVE's for CAPEC-439\n",
      "Found: CVE-2019-13945, CVE-2018-4251, \n",
      "\n",
      "\n",
      "Searching CVE's for CAPEC-158\n",
      "Found: CVE-2009-2272, CVE-2009-1466, CVE-2009-0152, CVE-2009-1603, CVE-2009-0964, CVE-2008-6157, CVE-2008-6828, CVE-2008-1567, CVE-2008-0174, CVE-2007-5778, CVE-2002-1949, CVE-2008-4122, CVE-2008-3289, CVE-2008-4390, CVE-2007-5626, CVE-2004-1852, CVE-2008-0374, CVE-2007-4961, CVE-2007-4786, CVE-2005-3140, \n",
      "\n",
      "\n",
      "Searching CVE's for CAPEC-311\n",
      "Found: \n",
      "\n",
      "\n",
      "Searching CVE's for CAPEC-93\n",
      "Found: CVE-2006-4624, CVE-2002-0542, CVE-2000-0703, CVE-2002-0986, CVE-2003-0020, CVE-2003-0083, CVE-2003-0021, CVE-2003-0022, CVE-2003-0023, CVE-2003-0063, CVE-2000-0476, CVE-2001-1556, \n",
      "\n",
      "\n",
      "Searching CVE's for CAPEC-309\n",
      "Found: CVE-2001-1483, CVE-2001-1528, CVE-2004-2150, CVE-2005-1205, CVE-2002-1725, CVE-2002-0515, CVE-2004-0778, CVE-2000-1117, CVE-2003-0190, CVE-2008-2049, CVE-2007-5172, CVE-2008-4638, CVE-2007-1409, CVE-2005-0603, CVE-2004-2268, CVE-2003-1078, \n",
      "\n",
      "\n",
      "Searching CVE's for CAPEC-227\n",
      "Found: CVE-2020-3566, CVE-2009-2874, CVE-2009-1928, CVE-2009-2858, CVE-2009-2726, CVE-2009-2540, CVE-2009-2299, CVE-2009-2054, CVE-2008-5180, CVE-2008-2121, CVE-2008-2122, CVE-2008-1700, CVE-2007-4103, CVE-2006-1173, CVE-2007-0897, \n",
      "\n",
      "\n",
      "Searching CVE's for CAPEC-131\n",
      "Found: CVE-1999-1127, CVE-2001-0830, CVE-2002-1372, \n",
      "\n",
      "\n",
      "Searching CVE's for CAPEC-130\n",
      "Found: CVE-1999-1127, CVE-2001-0830, CVE-2002-1372, CVE-2009-4017, CVE-2009-2726, CVE-2009-2540, CVE-2009-2054, CVE-2008-5180, CVE-2008-1700, CVE-2005-4650, CVE-2020-15100, CVE-2020-36049, CVE-2019-20176, CVE-2013-1591, \n",
      "\n",
      "\n",
      "Searching CVE's for CAPEC-125\n",
      "Found: CVE-1999-1127, CVE-2001-0830, CVE-2002-1372, CVE-2009-4017, CVE-2009-2726, CVE-2009-2540, CVE-2009-2054, CVE-2008-5180, CVE-2008-1700, CVE-2005-4650, CVE-2020-15100, \n",
      "\n",
      "Finished in 00h 16m and 41.62s.\n"
     ]
    }
   ],
   "source": [
    "t_cwe_cve_dict = find_cwe_for_capec(techniques_capecs,fs)\n",
    "write_dict_to_file(t_cwe_cve_dict, \"./scans/t-cwe-cve-dict.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  },
  "vscode": {
   "interpreter": {
    "hash": "47db1063135b9dd4721fd89f08412a58c1c84816528ace670b134fbcd379712a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
